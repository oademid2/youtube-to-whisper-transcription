{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv # add this line\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch  # install steps: pytorch.org\n",
    "\n",
    "from tqdm.auto import tqdm  # !pip install tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = whisper.load_model(\"base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import googleapiclient.discovery\n",
    "import urllib.parse as p\n",
    "import pandas as pd\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import json\n",
    "def obj_dict(obj):\n",
    "    return obj.__dict__\n",
    "\n",
    "import subprocess\n",
    "import requests\n",
    "import re\n",
    "import youtube_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube  # !pip install pytube\n",
    "from pytube.exceptions import RegexMatchError\n",
    "from tqdm.auto import tqdm  # !pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable OAuthlib's HTTPS verification when running locally.\n",
    "# *DO NOT* leave this option enabled in production.\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = os.getenv('DEVELOPER_KEY')\n",
    "\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey = DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "# Use a service account.\n",
    "cred = credentials.Certificate('../analytics-c4f16-firebase-adminsdk-plgdk-2a3d65b3a8.json')\n",
    "\n",
    "app = firebase_admin.initialize_app(cred)\n",
    "\n",
    "db = firestore.client(app)\n",
    "batch = db.batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nested_dict_keys(dic, keys):\n",
    "    d = dic\n",
    "    for key in keys:\n",
    "        if key in d.keys():\n",
    "            d = d[key]\n",
    "            continue\n",
    "        else:\n",
    "            return dic['snippet']['thumbnails']['default']['url'] \n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseHelper():\n",
    "    \n",
    "    def __init__(self, db):\n",
    "        self.db = db\n",
    "        self.CHANNELS = None\n",
    "        self.VIDEOS = {}\n",
    "    \n",
    "    def get_channel_db(self,db):\n",
    "        docs = self.db.collection(u'channels').stream()\n",
    "        channelsCollection = {}\n",
    "        for doc in docs:\n",
    "            channelsCollection[doc.id]=doc.to_dict()\n",
    "        return channelsCollection\n",
    "    \n",
    "    def set_channels(self):\n",
    "        self.CHANNELS = self.get_channel_db(db)\n",
    "        \n",
    "    def set_videos(self,_id,videos):\n",
    "        self.VIDEOS[_id] = videos\n",
    "\n",
    "    def get_channel_videos(self,channelId):\n",
    "\n",
    "        docs = db.collection(u'Videos').order_by('publishedAt', direction=firestore.Query.DESCENDING).where(u\"channelID\",u\"==\",u\"{}\".format(channelId)).stream()\n",
    "\n",
    "        collection = []\n",
    "        for doc in docs:\n",
    "            vid =doc.to_dict()\n",
    "            if \"#shorts\" not in vid['title']:\n",
    "                collection.append(vid)\n",
    "        return collection\n",
    "    \n",
    "    def get_channel_doc(self, video_url, allChannels):\n",
    "        channel_id = video_url_to_channel_id(video_url)\n",
    "        print(channel_id)\n",
    "\n",
    "        for record in allChannels.values():\n",
    "            if record['channelId'] == channel_id:\n",
    "                print(\"Channel {} already exists.\".format(record['title']))\n",
    "                return record\n",
    "\n",
    "        channelToAdd = generate_channel_json(video_url)    \n",
    "\n",
    "\n",
    "        add = input(\"Create channel for url ? (0 for no, any other key for yes)\".format(channelToAdd['title']))\n",
    "\n",
    "        if add == 0:\n",
    "            print(\"No channel for url\")\n",
    "            return\n",
    "\n",
    "\n",
    "        docRef = db.collection(u\"channels\").document(u\"{}\".format(channelToAdd['channelId'])).set(channelToAdd)\n",
    "        print(\"Channel {} is created.\".format(channelToAdd['title']))\n",
    "        return channelToAd\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_channel_json(sourceValue, source=\"url\"):\n",
    "    \n",
    "    if source==\"id\":\n",
    "        channel_id = sourceValue\n",
    "    elif source==\"url\":\n",
    "        video_url = sourceValue\n",
    "        channel_id = video_url_to_channel_id(video_url)\n",
    "    else:\n",
    "        raise Exception(\"{} not a valid source.\".format(source))\n",
    "            \n",
    "    request = youtube.channels().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            id=channel_id\n",
    "        )\n",
    "    response = request.execute()\n",
    "    \n",
    "    channel_df = {}#pd.DataFrame(columns=['channelId', 'title', 'uploads','description','thumbnail'])\n",
    "    channel_df['channelId'] = channel_id\n",
    "    channel_df['title'] = response['items'][0]['snippet']['title']\n",
    "    channel_df['uploads'] = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    channel_df['description'] = response['items'][0]['snippet']['description']\n",
    "    channel_df['thumbnail'] = check_nested_dict_keys(response['items'][0],[\"snippet\",\"thumbnails\",\"high\",\"url\"])\n",
    "    channel_df['videos'] = []\n",
    "    \n",
    "    #full_channel_df = pd.concat([full_channel_df, pd.DataFrame.from_dict(channel_df)])\n",
    "\n",
    "    return channel_df\n",
    "\n",
    "def video_url_to_channel_id(video_url):\n",
    "    video_param_from_url = video_url.split(\"/watch?v=\")[1].split(\"&\")[0]\n",
    "    request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            id=video_param_from_url\n",
    "        )\n",
    "    response = request.execute()\n",
    "    channel_id = response['items'][0]['snippet']['channelId']\n",
    "    return channel_id\n",
    "\n",
    "\n",
    "def get_channel_doc(video_url, allChannels):\n",
    "    channel_id = video_url_to_channel_id(video_url)\n",
    "    print(channel_id)\n",
    "    \n",
    "    for record in allChannels.values():\n",
    "        if record['channelId'] == channel_id:\n",
    "            print(\"Channel {} already exists.\".format(record['title']))\n",
    "            return record\n",
    "\n",
    "    channelToAdd = generate_channel_json(video_url)    \n",
    "\n",
    "\n",
    "    add = input(\"Create channel for url ? (0 for no, any other key for yes)\".format(channelToAdd['title']))\n",
    "\n",
    "    if add == 0:\n",
    "        print(\"No channel for url\")\n",
    "        return\n",
    "    \n",
    "\n",
    "    docRef = db.collection(u\"channels\").document(u\"{}\".format(channelToAdd['channelId'])).set(channelToAdd)\n",
    "    print(\"Channel {} is created.\".format(channelToAdd['title']))\n",
    "    return channelToAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uploads_id(youtube, channel_id):\n",
    "    request = youtube.channels().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            id=channel_id\n",
    "        )\n",
    "    response = request.execute()\n",
    "    return response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "\n",
    "def get_uploaded_videos_response(youtube, channel_id,**args):\n",
    "    \n",
    "    playlist_id = get_uploads_id(youtube, channel_id)\n",
    "    max_total=args.get(\"max_total\") if args.get(\"max_total\") else 1000\n",
    "    oldest_date=args.get(\"oldest_date\") if args.get(\"oldest_date\") else False\n",
    "\n",
    "    \n",
    "    params = {\n",
    "        \"part\":\"snippet,contentDetails\",\n",
    "        \"playlistId\": playlist_id,\n",
    "        \"maxResults\": 50\n",
    "    }\n",
    "    \n",
    "    uploaded_videos_content_details_list = []\n",
    "\n",
    "    while True:\n",
    "        response = youtube.playlistItems().list(**params).execute()\n",
    "        \n",
    "        \n",
    "        if oldest_date:\n",
    "                \n",
    "            oldestResponseDate = response.get('items')[-1]['snippet']['publishedAt'].split(\"T\")[0]\n",
    "            if oldestResponseDate <= oldest_date:\n",
    "                add_response = []\n",
    "                for r in response.get('items'):\n",
    "                    date = r['snippet']['publishedAt'].split(\"T\")[0]\n",
    "                    if date <= oldest_date:\n",
    "                        break\n",
    "                    else:\n",
    "                        add_response.append(r)\n",
    "                videos_list = uploaded_videos_content_details_list + add_response\n",
    "                print(\"New videos found: {}\".format(len(videos_list)))\n",
    "                print(\"Newest video: {}, {}\".format(videos_list[0]['snippet']['title'],videos_list[0]['snippet']['publishedAt']))\n",
    "                print(\"Oldest video: {}, {}\".format(videos_list[-1]['snippet']['title'],videos_list[-1]['snippet']['publishedAt']))\n",
    "\n",
    "\n",
    "                return videos_list\n",
    "\n",
    "      \n",
    "        uploaded_videos_content_details_list = uploaded_videos_content_details_list + response.get('items')\n",
    "        \n",
    "        if (max_total and len(uploaded_videos_content_details_list) >= max_total):\n",
    "            return uploaded_videos_content_details_list[:max_total]\n",
    "     \n",
    "        elif 'nextPageToken' in response.keys():\n",
    "            params['pageToken'] = response['nextPageToken']\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return uploaded_videos_content_details_list\n",
    "\n",
    "def getYoutubeDuration(videoId):\n",
    "    responseVideoDetails = youtube.videos().list( part=\"contentDetails\",id=videoId).execute()\n",
    "    durationResponse=responseVideoDetails['items'][0]['contentDetails']['duration']\n",
    "\n",
    "    duration_string = durationResponse.replace('PT',\"\")\n",
    "    number_values = re.findall('\\d+',duration_string)\n",
    "    symbols_available= ''.join([i for i in duration_string if not i.isdigit()])\n",
    "    symbol_map = {}\n",
    "    for symbol in 'HMS':\n",
    "        index = symbols_available.find(symbol)\n",
    "        if index > -1:\n",
    "            symbol_map[symbol] = number_values[index]\n",
    "\n",
    "    duration = 0\n",
    "\n",
    "\n",
    "    for idx in symbol_map:\n",
    "        if idx == \"H\":\n",
    "            duration = int(symbol_map[idx])*60*60 + duration\n",
    "        if idx == \"M\":\n",
    "            duration = int(symbol_map[idx])*60 + duration\n",
    "        if idx == \"S\":\n",
    "            duration = int(symbol_map[idx]) + duration\n",
    "            \n",
    "    return duration\n",
    "\n",
    "def video_response_list_to_list_of_dicts(response_list):\n",
    "    \n",
    "    list_of_dicts = []\n",
    "    for x in response_list:\n",
    "        if \"#shorts\" in x['snippet']['title']:\n",
    "            continue\n",
    "            \n",
    "        video_df = {}\n",
    "        video_df['id'] = x['id']\n",
    "        video_df['videoId'] = x['contentDetails']['videoId'] \n",
    "        video_df['title'] = x['snippet']['title'] \n",
    "        video_df['description'] = x['snippet']['description'] \n",
    "        video_df['thumbnail'] = check_nested_dict_keys(x,[\"snippet\",\"thumbnails\",\"maxres\",\"url\"])      \n",
    "        video_df['channelID'] = x['snippet']['channelId'] \n",
    "        video_df['videoId'] = x['contentDetails']['videoId'] \n",
    "        video_df['publishedAt'] =x['snippet']['publishedAt'].split(\"T\")[0] \n",
    "        video_df['videoUrl'] = \"https://www.youtube.com/watch?v={}\".format(x['contentDetails']['videoId'] )\n",
    "        video_df['duration'] = getYoutubeDuration(x['contentDetails']['videoId']  )\n",
    "        \n",
    "        video_df['text'] = ''\n",
    "#         video_df['assemblySentences'] ='' \n",
    "#         video_df['assemblyText'] ='' \n",
    "#         video_df['availability']=''\n",
    "#         video_df['assemblyId'] = ''\n",
    "#         video_df['ytaTranscript'] = ''\n",
    "#         video_df['mainTranscript'] = ''\n",
    "#         video_df['ytaAvailability'] = ''\n",
    "\n",
    "\n",
    "        list_of_dicts.append(video_df)\n",
    "\n",
    "\n",
    "    return list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullChannel(url, DB):\n",
    "\n",
    "    #Create channel\n",
    "    channel = get_channel_doc(url,DB.CHANNELS)\n",
    "    \n",
    "    videos_collections= DB.get_channel_videos(channel['channelId'])#load all videos\n",
    "    \n",
    "    DB.set_videos(channel['channelId'],videos_collections)\n",
    "    #check for videos not yet uploaded\n",
    "\n",
    "    new_video_responses = get_uploaded_videos_response(youtube, channel['channelId'],\n",
    "                                               oldest_date=videos_collections[0]['publishedAt'])\n",
    "\n",
    "    list_of_new_video_responses_as_dicts = video_response_list_to_list_of_dicts(new_video_responses)\n",
    "\n",
    "\n",
    "    return channel, list_of_new_video_responses_as_dicts\n",
    "\n",
    "#add videos to transcript execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript_object(video, text, segments,source):\n",
    "    item = {}\n",
    "    item['videoId'] = videoId\n",
    "    item['transcriptId'] = videoId\n",
    "    item['transcript'] = segments\n",
    "    item['text'] = text\n",
    "    item['type'] = segments\n",
    "    item['source'] = source\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(url):\n",
    "    yt = YouTube(url)\n",
    "    video = yt.streams.filter(only_audio=True).first()\n",
    "    out_file=video.download(output_path=\"\")\n",
    "    base, ext = os.path.splitext(out_file)\n",
    "    new_file = base+'.mp3'\n",
    "    os.rename(out_file, new_file)\n",
    "    a = new_file\n",
    "    return a\n",
    "\n",
    "def transcribe(video):\n",
    "    \n",
    "    metric = {}\n",
    "    result = {}\n",
    "\n",
    "    start = time.time()\n",
    "    _id = video['videoId']\n",
    "    print(video['videoUrl'])\n",
    "    \n",
    "    try:\n",
    "        get_audio(video['videoUrl'])\n",
    "        # transcribe to get speech-to-text data\n",
    "        result = model.transcribe('audio_files/{}.mp3'.format(_id))\n",
    "\n",
    "        # add results to data list\n",
    "        with open('transcript_files/{}.json'.format(_id), 'w', encoding='utf-8') as f:\n",
    "            json.dump(result, f, ensure_ascii=False, indent=4)\n",
    "        os.remove(\"audio_files/{}.mp3\".form)\n",
    "        source = \"whisper\"\n",
    "        \n",
    "\n",
    "    except Exception as e: # work on python 3.x\n",
    "     \n",
    "        print(e)\n",
    "        try:\n",
    "            print('could not get streaming data')\n",
    "            ydl_opts = {'format': 'bestaudio'}\n",
    "\n",
    "\n",
    "            ydl =youtube_dl.YoutubeDL(ydl_opts)\n",
    "\n",
    "            videoUrl = video['videoUrl']\n",
    "            info = ydl.extract_info(videoUrl, download=False)\n",
    "            audioUrl = info['formats'][0]['url']\n",
    "            requestForTrancript = postTranscript(audioUrl)\n",
    "            source = \"pendng\"\n",
    "        except Exception as e: # work on python 3.x\n",
    "            print(e)\n",
    "            print('could not get assembly data')\n",
    "\n",
    "            source = \"fail\"\n",
    "\n",
    "\n",
    "    \n",
    "    metric['id'] = path\n",
    "    metric['time'] = time.time() - start\n",
    "    \n",
    "    return result, metric,source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_audio(\"https://www.youtube.com/watch?v=7hrSj5qkHv4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = DatabaseHelper(db)\n",
    "DB.set_channels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCamLstJyCa-t5gfZegxsFMw\n",
      "Channel Colin and Samir already exists.\n"
     ]
    },
    {
     "ename": "FailedPrecondition",
     "evalue": "400 The query requires an index. You can create it here: https://console.firebase.google.com/v1/r/project/analytics-c4f16/firestore/indexes?create_composite=Ck5wcm9qZWN0cy9hbmFseXRpY3MtYzRmMTYvZGF0YWJhc2VzLyhkZWZhdWx0KS9jb2xsZWN0aW9uR3JvdXBzL1ZpZGVvcy9pbmRleGVzL18QARoNCgljaGFubmVsSUQQARoPCgtwdWJsaXNoZWRBdBACGgwKCF9fbmFtZV9fEAI",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m             return _StreamingResponseIterator(\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefetch_first_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefetch_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wrapped, prefetch_first_result)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprefetch_first_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stored_first_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"The query requires an index. You can create it here: https://console.firebase.google.com/v1/r/project/analytics-c4f16/firestore/indexes?create_composite=Ck5wcm9qZWN0cy9hbmFseXRpY3MtYzRmMTYvZGF0YWJhc2VzLyhkZWZhdWx0KS9jb2xsZWN0aW9uR3JvdXBzL1ZpZGVvcy9pbmRleGVzL18QARoNCgljaGFubmVsSUQQARoPCgtwdWJsaXNoZWRBdBACGgwKCF9fbmFtZV9fEAI\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.33.170:443 {created_time:\"2022-12-21T22:19:12.674922-05:00\", grpc_status:9, grpc_message:\"The query requires an index. You can create it here: https://console.firebase.google.com/v1/r/project/analytics-c4f16/firestore/indexes?create_composite=Ck5wcm9qZWN0cy9hbmFseXRpY3MtYzRmMTYvZGF0YWJhc2VzLyhkZWZhdWx0KS9jb2xsZWN0aW9uR3JvdXBzL1ZpZGVvcy9pbmRleGVzL18QARoNCgljaGFubmVsSUQQARoPCgtwdWJsaXNoZWRBdBACGgwKCF9fbmFtZV9fEAI\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3f5bfa4d2f89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.youtube.com/watch?v=lBCOOTyU46M&t=512s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_videos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpullChannel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-5cf2f6b24560>\u001b[0m in \u001b[0;36mpullChannel\u001b[0;34m(url, DB)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_channel_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHANNELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvideos_collections\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mDB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_channel_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channelId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#load all videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mDB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channelId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvideos_collections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ebddf04fd6c9>\u001b[0m in \u001b[0;36mget_channel_videos\u001b[0;34m(self, channelId)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mcollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mvid\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"#shorts\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/google/cloud/firestore_v1/query.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, transaction, retry, timeout)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mtransaction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         )\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/google/cloud/firestore_v1/query.py\u001b[0m in \u001b[0;36m_get_stream_iterator\u001b[0;34m(self, transaction, retry, timeout)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rpc_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/google/cloud/firestore_v1/services/firestore/client.py\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m             \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1308\u001b[0m         )\n\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             )\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             )\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m: 400 The query requires an index. You can create it here: https://console.firebase.google.com/v1/r/project/analytics-c4f16/firestore/indexes?create_composite=Ck5wcm9qZWN0cy9hbmFseXRpY3MtYzRmMTYvZGF0YWJhc2VzLyhkZWZhdWx0KS9jb2xsZWN0aW9uR3JvdXBzL1ZpZGVvcy9pbmRleGVzL18QARoNCgljaGFubmVsSUQQARoPCgtwdWJsaXNoZWRBdBACGgwKCF9fbmFtZV9fEAI"
     ]
    }
   ],
   "source": [
    "url= \"https://www.youtube.com/watch?v=lBCOOTyU46M&t=512s\"\n",
    "channel, new_videos = pullChannel(url,DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = new_videos.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_videos = new_videos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "metrics= []\n",
    "\n",
    "for doc in new_videos:\n",
    "\n",
    "    result, metric, source = transcribe(doc)\n",
    "    \n",
    "    if source == \"whisper\":\n",
    "        data.extend(result)\n",
    "        metrics.extend(metric)\n",
    "\n",
    "        doc['text'] = result['text']\n",
    "        transcript = transcript_object(doc, result['segments'], source)\n",
    "    \n",
    "        docRef = DB.db.collection(u\"Videos\").document(u\"{}\".format(doc['videoId'])).set(doc)\n",
    "        docRef = DB.db.collection(u\"Transcripts\").document(u\"{}\".format(doc['videoId'])).set(transcript)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        doc['text'] = 'error'\n",
    "        transcript = transcript_object(doc, result['segments'], source)\n",
    "    \n",
    "#         docRef = DB.db.collection(u\"videos\").document(u\"{}\".format(doc['videoId'])).set(doc)\n",
    "#         docRef = DB.db.collection(u\"whisperTranscripts\").document(u\"{}\".format(doc['videoId'])).set(transcript)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Upload new videos\n",
    "#add = print(\"Input {} videos?\".format(len(new_videos)))\n",
    "\n",
    "data = []\n",
    "metrics= []\n",
    "\n",
    "for doc in list_of_video_responses_as_dicts:\n",
    "    print(\"a\")\n",
    "    result, metric = transcribe(doc)\n",
    "    \n",
    "    data.extend(result)\n",
    "    metrics.extend(metric)\n",
    "    \n",
    "    doc['text'] = result['text']\n",
    "    transcript = transcript_object(doc, result['segments'])\n",
    "    \n",
    "#         docRef = DB.db.collection(u\"videos\").document(u\"{}\".format(doc['videoId'])).set(doc)\n",
    "#         docRef = DB.db.collection(u\"whisperTranscripts\").document(u\"{}\".format(doc['videoId'])).set(transcript)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get channel\n",
    "#get all videos from channel\n",
    "#If videos do not exist yet add it to list of what to add\n",
    "#for list of what to add > add, download, transcribe>update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Complex:\n",
    "    def __init__(self, realpart, imagpart):\n",
    "        self.r = realpart\n",
    "        self.i = imagpart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = get_channel_doc(\"https://www.youtube.com/watch?v=dbOXYhjpXAc&t=937s&ab_channel=ColinandSamir\", channels_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(url):\n",
    "    yt = YouTube(url)\n",
    "    video = yt.streams.filter(only_audio=True).first()\n",
    "    out_file=video.download(output_path=\"\")\n",
    "    base, ext = os.path.splitext(out_file)\n",
    "    new_file = base+'.mp3'\n",
    "    os.rename(out_file, new_file)\n",
    "    a = new_file\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(video):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    _id = video['videoId']\n",
    "    get_audio(video['videoUrl'])\n",
    "    # transcribe to get speech-to-text data\n",
    "    result = model.transcribe('audio_files/{}.mp3'.format(_id))\n",
    "    \n",
    "    # add results to data list\n",
    "    with open('transcript_files/{}.json'.format(_id), 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=4)\n",
    "    os.remove(\"audio_files/{}.mp3\".form)\n",
    "    data.extend(result['segments'])\n",
    "\n",
    "    metric = {}\n",
    "    metric['id'] = path\n",
    "    metric['time'] = time.time() - start\n",
    "    metrics.extend(metric)\n",
    "    \n",
    "    return result, metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def\n",
    "data = []\n",
    "metrics = []\n",
    "\n",
    "\n",
    "for i, path in enumerate(tqdm(paths)):\n",
    "    start = time.time()\n",
    "\n",
    "    _id = path.split('')[-1][:-4]\n",
    "    # transcribe to get speech-to-text data\n",
    "    #result = model.transcribe(path)\n",
    "    # add results to data list\n",
    "    with open('transcript_files/{}.json'.format(_id), 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=4)\n",
    "    os.remove(\"audio_files/{}.mp3\".form)\n",
    "    data.extend(result['segments'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    metric = {}\n",
    "    metric['id'] = path\n",
    "    metric['time'] = start - time.time()\n",
    "    metric['int'] = i\n",
    "    metrics.extend(metric)\n",
    "\n",
    "    break  # this is just part of the loop used as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of MP3 audio files\n",
    "paths = [str(x) for x in Path('audio_files').glob('*.mp3')]\n",
    "print(len(paths))\n",
    "print(paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def\n",
    "data = []\n",
    "metrics = []\n",
    "\n",
    "\n",
    "for i, path in enumerate(tqdm(paths)):\n",
    "    start = time.time()\n",
    "\n",
    "    _id = path.split('/')[-1][:-4]\n",
    "    # transcribe to get speech-to-text data\n",
    "    #result = model.transcribe(path)\n",
    "    # add results to data list\n",
    "    with open('transcript_files/{}.json'.format(_id), 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=4)\n",
    "    os.remove(\"audio_files/{}.mp3\".form)\n",
    "    data.extend(result['segments'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    metric = {}\n",
    "    metric['id'] = path\n",
    "    metric['time'] = start - time.time()\n",
    "    metric['int'] = i\n",
    "    metrics.extend(metric)\n",
    "\n",
    "    break  # this is just part of the loop used as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"audio_files/FOOTBALL CHALLENGES vs MBAPPE & NEYMAR.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
