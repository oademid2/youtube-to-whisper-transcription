{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import googleapiclient.discovery\n",
    "import urllib.parse as p\n",
    "import pandas as pd\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import json\n",
    "def obj_dict(obj):\n",
    "    return obj.__dict__\n",
    "\n",
    "import subprocess\n",
    "import requests\n",
    "import re\n",
    "import youtube_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv # add this line\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "# Use a service account.\n",
    "cred = credentials.Certificate('../analytics-c4f16-firebase-adminsdk-plgdk-2a3d65b3a8.json')\n",
    "\n",
    "app = firebase_admin.initialize_app(cred)\n",
    "\n",
    "db = firestore.client(app)\n",
    "batch = db.batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable OAuthlib's HTTPS verification when running locally.\n",
    "# *DO NOT* leave this option enabled in production.\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = os.getenv('DEVELOPER_KEY')\n",
    "\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey = DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nested_dict_keys(dic, keys):\n",
    "    d = dic\n",
    "    for key in keys:\n",
    "        if key in d.keys():\n",
    "            d = d[key]\n",
    "            continue\n",
    "        else:\n",
    "            return dic['snippet']['thumbnails']['default']['url'] \n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_collection_to_list(docs):\n",
    "    collection = {}\n",
    "    for doc in docs:\n",
    "        collection[doc.id]=doc.to_dict()\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_db_list_filter(name,channelId,order_by=None):\n",
    "\n",
    "    if order_by:\n",
    "        docs = db.collection(u'{}'.format(name)).order_by(order_by, direction=firestore.Query.DESCENDING).where(u\"channelID\",u\"==\",u\"{}\".format(channelId)).stream()\n",
    "    else:\n",
    "        docs = db.collection(u'{}'.format(name)).where(u\"channelID\",u\"==\",u\"{}\".format(channelId)).stream()\n",
    "\n",
    "    collection = []\n",
    "    for doc in docs:\n",
    "        vid =doc.to_dict()\n",
    "        if \"#shorts\" not in vid['title']:\n",
    "            collection.append(vid)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_db():\n",
    "    docs = db.collection(u'channels').stream()\n",
    "    channelsCollection = {}\n",
    "    for doc in docs:\n",
    "        channelsCollection[doc.id]=doc.to_dict()\n",
    "    return channelsCollection\n",
    "\n",
    "def generate_channel_json(sourceValue, source=\"url\"):\n",
    "    \n",
    "    if source==\"id\":\n",
    "        channel_id = sourceValue\n",
    "    elif source==\"url\":\n",
    "        video_url = sourceValue\n",
    "        channel_id = video_url_to_channel_id(video_url)\n",
    "    else:\n",
    "        raise Exception(\"{} not a valid source.\".format(source))\n",
    "            \n",
    "    request = youtube.channels().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            id=channel_id\n",
    "        )\n",
    "    response = request.execute()\n",
    "    \n",
    "    channel_df = {}#pd.DataFrame(columns=['channelId', 'title', 'uploads','description','thumbnail'])\n",
    "    channel_df['channelId'] = channel_id\n",
    "    channel_df['title'] = response['items'][0]['snippet']['title']\n",
    "    channel_df['uploads'] = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    channel_df['description'] = response['items'][0]['snippet']['description']\n",
    "    channel_df['thumbnail'] = check_nested_dict_keys(response['items'][0],[\"snippet\",\"thumbnails\",\"high\",\"url\"])\n",
    "\n",
    "    #full_channel_df = pd.concat([full_channel_df, pd.DataFrame.from_dict(channel_df)])\n",
    "\n",
    "    return channel_df\n",
    "\n",
    "def video_url_to_channel_id(video_url):\n",
    "    video_param_from_url = video_url.split(\"/watch?v=\")[1].split(\"&\")[0]\n",
    "    request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            id=video_param_from_url\n",
    "        )\n",
    "    response = request.execute()\n",
    "    channel_id = response['items'][0]['snippet']['channelId']\n",
    "    return channel_id\n",
    "\n",
    "\n",
    "def get_channel_doc(video_url, allChannels):\n",
    "    channel_id = video_url_to_channel_id(video_url)\n",
    "    print(channel_id)\n",
    "    \n",
    "    for record in allChannels.values():\n",
    "        if record['channelId'] == channel_id:\n",
    "            print(\"Channel {} already exists.\".format(record['title']))\n",
    "            return record\n",
    "\n",
    "    channelToAdd = generate_channel_json(video_url)    \n",
    "\n",
    "\n",
    "    add = input(\"Create channel for url ? (0 for no, any other key for yes)\".format(channelToAdd['title']))\n",
    "\n",
    "    if add == 0:\n",
    "        print(\"No channel for url\")\n",
    "        return\n",
    "    \n",
    "\n",
    "    docRef = db.collection(u\"channels\").document(u\"{}\".format(channelToAdd['channelId'])).set(channelToAdd)\n",
    "    print(\"Channel {} is created.\".format(channelToAdd['title']))\n",
    "    return channelToAdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uploads_id(youtube, channel_id):\n",
    "    request = youtube.channels().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            id=channel_id\n",
    "        )\n",
    "    response = request.execute()\n",
    "    return response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "\n",
    "def get_uploaded_videos_response(youtube, channel_id,**args):\n",
    "    \n",
    "    playlist_id = get_uploads_id(youtube, channel_id)\n",
    "    max_total=args.get(\"max_total\") if args.get(\"max_total\") else 1000\n",
    "    oldest_date=args.get(\"oldest_date\") if args.get(\"oldest_date\") else False\n",
    "\n",
    "    \n",
    "    params = {\n",
    "        \"part\":\"snippet,contentDetails\",\n",
    "        \"playlistId\": playlist_id,\n",
    "        \"maxResults\": 50\n",
    "    }\n",
    "    \n",
    "    uploaded_videos_content_details_list = []\n",
    "\n",
    "    while True:\n",
    "        response = youtube.playlistItems().list(**params).execute()\n",
    "        \n",
    "        \n",
    "        if oldest_date:\n",
    "            oldestResponseDate = response.get('items')[-1]['snippet']['publishedAt'].split(\"T\")[0]\n",
    "            if oldestResponseDate <= oldest_date:\n",
    "                add_response = []\n",
    "                for r in response.get('items'):\n",
    "                    date = r['snippet']['publishedAt'].split(\"T\")[0]\n",
    "                    if date <= oldest_date:\n",
    "                        break\n",
    "                    else:\n",
    "                        add_response.append(r)\n",
    "                videos_list = uploaded_videos_content_details_list + add_response\n",
    "                print(\"New videos found: {}\".format(len(videos_list)))\n",
    "                print(\"Newest video: {}, {}\".format(videos_list[0]['snippet']['title'],videos_list[0]['snippet']['publishedAt']))\n",
    "                print(\"Oldest video: {}, {}\".format(videos_list[-1]['snippet']['title'],videos_list[-1]['snippet']['publishedAt']))\n",
    "\n",
    "\n",
    "      \n",
    "        uploaded_videos_content_details_list = uploaded_videos_content_details_list + response.get('items')\n",
    "        \n",
    "        if (max_total and len(uploaded_videos_content_details_list) >= max_total):\n",
    "            return uploaded_videos_content_details_list[:max_total]\n",
    "     \n",
    "        elif 'nextPageToken' in response.keys():\n",
    "            params['pageToken'] = response['nextPageToken']\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return uploaded_videos_content_details_list\n",
    "\n",
    "def getYoutubeDuration(videoId):\n",
    "    responseVideoDetails = youtube.videos().list( part=\"contentDetails\",id=videoId).execute()\n",
    "    print(videoId)\n",
    "    durationResponse=responseVideoDetails['items'][0]['contentDetails']['duration']\n",
    "\n",
    "    duration_string = durationResponse.replace('PT',\"\")\n",
    "    number_values = re.findall('\\d+',duration_string)\n",
    "    symbols_available= ''.join([i for i in duration_string if not i.isdigit()])\n",
    "    symbol_map = {}\n",
    "    for symbol in 'HMS':\n",
    "        index = symbols_available.find(symbol)\n",
    "        if index > -1:\n",
    "            symbol_map[symbol] = number_values[index]\n",
    "\n",
    "    duration = 0\n",
    "\n",
    "\n",
    "    for idx in symbol_map:\n",
    "        if idx == \"H\":\n",
    "            duration = int(symbol_map[idx])*60*60 + duration\n",
    "        if idx == \"M\":\n",
    "            duration = int(symbol_map[idx])*60 + duration\n",
    "        if idx == \"S\":\n",
    "            duration = int(symbol_map[idx]) + duration\n",
    "            \n",
    "    return duration\n",
    "def video_response_list_to_list_of_dicts(response_list):\n",
    "    \n",
    "    list_of_dicts = []\n",
    "    for x in response_list:\n",
    "        if \"#shorts\" in x['snippet']['title']:\n",
    "            continue\n",
    "            \n",
    "        video_df = {}\n",
    "        video_df['id'] = x['id']\n",
    "        video_df['videoId'] = x['contentDetails']['videoId'] \n",
    "        video_df['title'] = x['snippet']['title'] \n",
    "        video_df['description'] = x['snippet']['description'] \n",
    "        video_df['thumbnail'] = check_nested_dict_keys(x,[\"snippet\",\"thumbnails\",\"maxres\",\"url\"])      \n",
    "        video_df['channelID'] = x['snippet']['channelId'] \n",
    "        video_df['videoId'] = x['contentDetails']['videoId'] \n",
    "        video_df['publishedAt'] =x['snippet']['publishedAt'].split(\"T\")[0] \n",
    "        video_df['videoUrl'] = \"https://www.youtube.com/watch?v={}\".format(x['contentDetails']['videoId'] )\n",
    "        video_df['duration'] = getYoutubeDuration(x['contentDetails']['videoId']  )\n",
    "        \n",
    "        video_df['audioUrl'] = ''\n",
    "        video_df['assemblySentences'] ='' \n",
    "        video_df['assemblyText'] ='' \n",
    "        video_df['availability']=''\n",
    "        video_df['assemblyId'] = ''\n",
    "        video_df['ytaTranscript'] = ''\n",
    "        video_df['mainTranscript'] = ''\n",
    "        video_df['ytaAvailability'] = ''\n",
    "\n",
    "\n",
    "        list_of_dicts.append(video_df)\n",
    "\n",
    "\n",
    "    return list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yta_transcript_to_dicts(video_id):\n",
    "    response = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    list_of_dicts = []\n",
    "    \n",
    "    for x in response:\n",
    "        transcript_df={}\n",
    "        transcript_df['text'] = x[\"text\"]\n",
    "        transcript_df['start'] = x[\"start\"]\n",
    "        transcript_df['videoId'] = video_id\n",
    "        transcript_df['transcriptId'] = str(video_id)+\"_\"+str(x['start'])\n",
    "  \n",
    "        transcript_df['prevId'] = 0\n",
    "        transcript_df['nextId'] = 0\n",
    "        transcript_df['num_words'] = 0\n",
    "        transcript_df['word_index'] = 0\n",
    "        list_of_dicts.append(transcript_df)\n",
    "        \n",
    "    return list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postTranscript(url):\n",
    "    endpoint = \"https://api.assemblyai.com/v2/transcript\"\n",
    "    json = {\n",
    "        \"audio_url\": url,\n",
    "        \"auto_highlights\": True,\n",
    "        \"iab_categories\": True\n",
    "    }\n",
    "    headers = {\n",
    "        \"authorization\": \"d894d2a3c49040a49c6567373feb89e7\",\n",
    "    }\n",
    "    response = requests.post(endpoint, json=json,headers=headers)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCost(videoList):\n",
    "    cost = 0\n",
    "    for vid in videoList:\n",
    "        cost = vid['duration']*0.00025 + cost\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitAssemblyTranscripts(video_list):\n",
    "    ydl_opts = {'format': 'bestaudio'}\n",
    "\n",
    "\n",
    "    ydl =youtube_dl.YoutubeDL(ydl_opts)\n",
    "    pending_videos =[]\n",
    "    for doc in video_list:\n",
    "        videoUrl = \"https://www.youtube.com/watch?v={}\".format(doc['videoId'])\n",
    "        info = ydl.extract_info(videoUrl, download=False)\n",
    "        audioUrl = info['formats'][0]['url']\n",
    "        doc['audioUrl'] = audioUrl\n",
    "        \n",
    "        try:\n",
    "            response = getTranscript(doc['assemblyId'])\n",
    "            if 'sentences' in response:\n",
    "                print(\"Assembly Transcript already available for {} {}\".format(doc['title'],doc['videoId']))\n",
    "                continue\n",
    "            \n",
    "        except:\n",
    "            doc_ref = db.collection(u'AssemblyTranscripts').document(u'{}'.format(doc['videoId']))\n",
    "\n",
    "            doc = doc_ref.get()\n",
    "            if doc.exists:\n",
    "                print(\"Assembly Transcript already available for {} {}\".format(doc['title'],doc['videoId']))\n",
    "                continue\n",
    "        requestForTrancript = postTranscript(audioUrl)\n",
    "        pending_videos.append(doc)\n",
    "        doc['assemblyId'] = requestForTrancript['id']\n",
    "        doc['availability'] = 'pending'\n",
    "        docRef = db.collection(u\"videos\").document(u\"{}\".format(doc['videoId'])).set(doc)\n",
    "        db.collection(u\"AssemblyTranscripts\").document(u\"{}\".format(doc['videoId'])).set(doc) \n",
    "        print(\"submitted {} of time {}\".format(doc['title'],doc['duration']))\n",
    "\n",
    "    print(\"{} videos added.\".format(len(pending_videos)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTranscript(transcriptId):\n",
    "    endpoint = \"https://api.assemblyai.com/v2/transcript/{}/sentences\".format(transcriptId)\n",
    "    headers = {\n",
    "        \"authorization\": \"d894d2a3c49040a49c6567373feb89e7\",\n",
    "    }\n",
    "    json = {\n",
    "        \"auto_highlights\": True,\n",
    "        \"iab_categories\": True\n",
    "    }\n",
    "    response = requests.get(endpoint, json=json,headers=headers)\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullAssemblyTranscripts(video_list):\n",
    "    failed_videos = []\n",
    "    good_videos = []\n",
    "    for vid in video_list:\n",
    "        response = getTranscript(vid['assemblyId'])\n",
    "        if 'error' in response:\n",
    "            print(\"ERROR: {} {}\".format(vid['videoId'], vid['title']))\n",
    "            failed_videos.append(vid)\n",
    "            vid['availability'] = 'error'\n",
    "            docRef = db.collection(u\"videos\").document(u\"{}\".format(vid['videoId'])).set(vid)\n",
    "            continue\n",
    "            \n",
    "        if 'sentences' in response:\n",
    "            sentences = response['sentences']\n",
    "            cleanResponse = [record.pop('words') for record in sentences]\n",
    "            sentencesList = [record['text'] for record in sentences]\n",
    "            vid['assemblyText'] = \" \".join(sentencesList)\n",
    "            vid['assemblySentences'] = json.dumps(sentences, default=obj_dict)\n",
    "            vid['availability'] = 'available.assembly'\n",
    "            vid['mainTranscript'] = vid['assemblyText']\n",
    "\n",
    "            docRef = db.collection(u\"videos\").document(u\"{}\".format(vid['videoId'])).set(vid)\n",
    "            print(\"Transcript update for {}\".format(vid['title']))\n",
    "            \n",
    "            good_videos.append(vid)\n",
    "        else:print(response)\n",
    "    return failed_videos, good_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def yta_transcript_to_dicts(video_id):\n",
    "    response = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    list_of_dicts = []\n",
    "\n",
    "    for x in response:\n",
    "        transcript_df={}\n",
    "        transcript_df['text'] = x[\"text\"]\n",
    "        transcript_df['start'] = x[\"start\"]\n",
    "        transcript_df['videoId'] = video_id\n",
    "\n",
    "        list_of_dicts.append(transcript_df)\n",
    "        \n",
    "    return list_of_dicts\n",
    "def pullYtaTranscripts(video_list):\n",
    "    failed_videos = []\n",
    "    good_videos = []\n",
    "\n",
    "    for vid in video_list:\n",
    "        \n",
    "        try:\n",
    "            response = yta_transcript_to_dicts(vid['id'])\n",
    "          \n",
    "            vid['transcript'] = \" \".join(response['text'])\n",
    "            vid['mainTranscript'] =  vid['transcript'] if vid['assemblyText'] == '' else vid['assemblyText']\n",
    "\n",
    "            docRef = db.collection(u\"videos\").document(u\"{}\".format(vid['videoId'])).set(vid)\n",
    "            print(\"Transcript update for {}\".format(vid['title']))\n",
    "            \n",
    "        except :\n",
    "\n",
    "            print(\"ERROR: {} {}\".format(vid['videoId'], vid['title']))\n",
    "            failed_videos.append(vid)\n",
    "            vid['ytaAvailability'] = 'error'\n",
    "            docRef = db.collection(u\"videos\").document(u\"{}\".format(vid['videoId'])).set(vid)\n",
    "            continue\n",
    "            \n",
    "    return failed_videos,good_videos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTranscripts():\n",
    "    endpoint = \"https://api.assemblyai.com/v2/transcript\"\n",
    "    headers = {\n",
    "        \"authorization\": \"d894d2a3c49040a49c6567373feb89e7\",\n",
    "    }\n",
    "    response = requests.get(endpoint, headers=headers).json()\n",
    "    transcripts = response['transcripts']\n",
    "    eq1=False\n",
    "    i=0\n",
    "    while response['page_details']['prev_url']:\n",
    "        endpoint = response['page_details']['prev_url']#response['page_details']['next_url']\n",
    "        response = requests.get(endpoint, headers=headers).json()\n",
    "        transcripts = transcripts + response['transcripts']\n",
    "        i=i+1\n",
    "    return transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullChannel(url, channels_collection):\n",
    "    \n",
    "    #Create channel\n",
    "    channel = get_channel_doc(url,channels_collection)\n",
    "    \n",
    "    #check for videos not yet uploaded\n",
    "    new_video_responses = get_uploaded_videos_response(youtube, channel['channelId'],\n",
    "                                               max_date=videos_collections[-1]['publishedAt'])\n",
    "    list_of_new_video_responses_as_dicts = video_response_list_to_list_of_dicts(new_video_responses)\n",
    "    \n",
    "    #Upload new videos\n",
    "    add = input(\"Input {} videos?\".format(len(list_of_new_video_responses_as_dicts)))\n",
    "    for doc in list_of_video_responses_as_dicts:\n",
    "        docRef = db.collection(u\"videos\").document(u\"{}\".format(doc['videoId'])).set(doc)\n",
    "        \n",
    "    return channel\n",
    "\n",
    "    #add videos to transcript execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_collection = get_channel_db()\n",
    "#docs = db.collection(u'{}'.format(name)).order_by(order_by, direction=firestore.Query.DESCENDING).where(u\"channelID\",u\"==\",u\"{}\".format(channelId)).stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCamLstJyCa-t5gfZegxsFMw\n",
      "Channel Colin and Samir already exists.\n"
     ]
    }
   ],
   "source": [
    "channel = get_channel_doc(\"https://www.youtube.com/watch?v=dbOXYhjpXAc&t=937s&ab_channel=ColinandSamir\", channels_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_collections=get_video_db_list_filter('videos',channel['channelId'],order_by='publishedAt')#load all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1t5oYKEn-1E\n",
      "gU24yrixXD8\n",
      "IjoTYJNr8DA\n",
      "xp2VGAjHZWY\n",
      "3QZkjsMfj3I\n",
      "gX0mrw1uZcY\n",
      "NphQGsm4rvk\n",
      "cbBxEmGOfk4\n",
      "lBCOOTyU46M\n",
      "OE4ti4alRN8\n",
      "w4iUuroktxw\n",
      "yNLqaQ6slkw\n",
      "N5YW4JB07-8\n",
      "gGBCbswZbnI\n",
      "0bC1ah_x8zo\n",
      "hYaGD0V2OkE\n",
      "wkDlfvTed1c\n",
      "7qoe2qhcZ-Y\n",
      "88067BiKU4Y\n",
      "jzMsnNxzejI\n",
      "iq71Cb2jEIE\n",
      "pvtMJFPyiLM\n",
      "3vbZvRHpM8w\n",
      "7hrSj5qkHv4\n",
      "VbNIh88Nq5k\n",
      "XuVR_elE1Pw\n",
      "r8bzWKBvZsE\n",
      "9CxaZWkwHzE\n",
      "x5lBJE2Ok8E\n",
      "z_czmz_bJqk\n",
      "irIN7SHvLDc\n",
      "t69cK3Ih_Og\n",
      "BB2HTaXTy0k\n",
      "HmrjOq8epsg\n",
      "MLyEDp7e0Q8\n",
      "9cn_r1z6zjo\n",
      "o8UBXsiiS24\n",
      "SpdWaOngRWM\n",
      "jz_qFyTrS8w\n",
      "Dh909TbYn7Y\n",
      "G5c6qof96DM\n",
      "UZSwDZ72Lp8\n",
      "dbOXYhjpXAc\n",
      "YVuIm8OLz-8\n",
      "r-Y1LRtsFaU\n",
      "_TAxmgPQtzc\n",
      "vwtRRdmZSYw\n",
      "xIC1nS4DU6M\n",
      "JoI4BRPd8us\n",
      "PiGCHXt5eBs\n",
      "6OICqRSTRjY\n",
      "71Xz6bYoRGc\n",
      "7PIlp-FSN5I\n",
      "vDGnnLLXGTo\n",
      "c8VcUnz3nVc\n",
      "TW7cH2wLv00\n",
      "dkIoObZOMbo\n",
      "BVEzAyZXctY\n",
      "dwFBlFS4dus\n",
      "p0Y82yGFqAw\n",
      "nxyThD3-GTw\n",
      "wUOdBXYIMM8\n",
      "pkiW9ygtddA\n",
      "O0C417mFrRQ\n",
      "ZlR0Rsu_VeU\n",
      "TAFYbWgX8K0\n",
      "rcHNOkA9NNk\n",
      "lQyAdgLwbLk\n",
      "HGhT5GMhf8A\n",
      "WVI2GUdJp2Y\n",
      "9w0kTRvOQWA\n",
      "j7eETkQcHLA\n",
      "5EfQqwDmOnI\n",
      "7eWpg3WyelA\n",
      "lBGq8vWx7B0\n",
      "lGmrpX7KkcU\n",
      "pVhrApLIraI\n",
      "f5WZgw0WGto\n",
      "Fz27v1gnCFM\n",
      "BSXMM9Y1blk\n",
      "TBx1uYdq5nk\n",
      "Xy0cKyWL2J8\n",
      "6R4zxswb8gQ\n",
      "knl2UOFr8bk\n",
      "jaKINKK09FY\n",
      "mwhbGLiDC3Q\n",
      "N3BA2RBRBT4\n",
      "wZrGJM7dGvY\n",
      "Sxh6Kai4tyI\n",
      "Ptk6P7Lc6rs\n",
      "pWH1TF1ZfKA\n",
      "Qg9hKz-AjIA\n",
      "9HsnKZnREgM\n",
      "g--OcS0WyHQ\n",
      "C6pngdRHaiI\n",
      "ZQrqhfe8kGE\n",
      "9ZaetFop0AA\n",
      "g5Ojh12HIrw\n",
      "GPX4PiwQz0U\n",
      "tSU8GEt2Ylg\n",
      "Nfqo3cGmrJ4\n",
      "fyt-E1A-jwc\n",
      "1WQbMVhIMEY\n",
      "5Xh8fAflpQY\n",
      "q-7x6jaTA-0\n",
      "ePAu90YVYMY\n",
      "y1QSLcAwiK0\n",
      "hPM7DDuzjZY\n",
      "q3oKPfPtT2Q\n",
      "QzNOBP7IiDY\n",
      "jNGUBzKadtw\n",
      "IMqiE_b5uPo\n",
      "9JrPkteJVS4\n",
      "lAMFzDc2zLE\n",
      "oopD9FX7a_c\n",
      "r-LAw78weAQ\n",
      "lh17G4AClKk\n",
      "6zoPS4SFhIc\n",
      "_MWqGYX78WE\n",
      "Bbt3HCz1b24\n",
      "Exm5p-vCjMs\n",
      "viFznUG5_bU\n",
      "uFDjvPZPig4\n",
      "XF2LLhd5jxg\n",
      "G7Yu6_3epOk\n",
      "WbZLhLCU5Ec\n",
      "fVtQKC2NK84\n",
      "PDZ6sYal5A0\n",
      "wLMNMGgJ_a0\n",
      "b7tBOJ7Hyl4\n",
      "WFe68voApTI\n",
      "6ZygdEyYpiE\n",
      "i4rwlQ7IA1U\n",
      "VaEXDJL8dfE\n",
      "vXgBYT9T7iM\n",
      "i05bI03nzv4\n",
      "fjZSLHvkg14\n",
      "TnyUCA-4BuQ\n",
      "c5mAdStj52c\n",
      "upYpZgh0tIU\n",
      "0T_HyckDSfA\n",
      "UkY8BIVEbx8\n",
      "7y1zfAPz2Rk\n",
      "xSTGLbguHYY\n",
      "sNGOgBcCcA4\n",
      "re_osGoZf9w\n",
      "j0JP6sL6sqA\n",
      "Bsm9a10hVbo\n",
      "enbVsRjRBSY\n",
      "m9YlMWwlgHQ\n",
      "Yk4KG9Vc2Hs\n",
      "zp9OCb3-mdQ\n",
      "Q1qmiTya2rc\n",
      "cX-Y-xtmVTI\n",
      "l_Naty_LoK4\n",
      "2RoG7Mhu5UI\n",
      "1YTwwAj0Pcw\n",
      "CI4weml_WWY\n",
      "SsQfHVetJdA\n",
      "OxsqnYbisB0\n",
      "EM-No65BGcc\n",
      "MqWVh1PYGt4\n",
      "cro1sY1GT78\n",
      "OXwKGWDvHfk\n",
      "x6-nKRHXUS0\n",
      "Rk5OEuBQgOM\n",
      "oSbFXT9Y-7g\n",
      "jx554F3BPKk\n",
      "0T4KT_vHX3Q\n",
      "XicLniORQgo\n",
      "vSfIMsnINsg\n",
      "K-hnbTqo6ko\n",
      "WoznWa7QTN4\n",
      "CBwQtl72k2A\n",
      "sCWdaLe2qJU\n",
      "pwkOf7A6hkw\n",
      "_DRsu5Cv3O0\n",
      "mOX0WpHZL0A\n",
      "vqp-87KaqTA\n",
      "e1rEmRRcOXA\n",
      "SuclRePmrso\n",
      "1D0wFMjVRQU\n",
      "nL8375jedtI\n",
      "71Dl3eKi78E\n",
      "rhx_VXSaSHQ\n",
      "zEXlzhjLkgY\n",
      "KNaqN8FfN3g\n",
      "zGQYGXXOo1A\n",
      "mY-ocubOA4Q\n",
      "20SF0ypIWF0\n",
      "acthJViewHY\n",
      "N3fmmRmlEQs\n",
      "o6IluoEuLdU\n",
      "x5z6kZ8Ms3A\n",
      "Fe4k7zYow_8\n",
      "rnd0dtbduZU\n",
      "x_XHWAQvV90\n",
      "HmSOib-jRHc\n",
      "2wVfZXL7wWQ\n",
      "uuqnJNQ_FlM\n",
      "oemgPLZKVFI\n",
      "CTtZZgyikC8\n",
      "pckdId5VMUI\n",
      "kIaMxe-Jdqk\n",
      "eGGWnRhJr-E\n",
      "VCBngh5dOgI\n",
      "Ua643jRnUqE\n",
      "vRE91dh0xXw\n",
      "qOmDq0nvmmk\n",
      "TwB7iy-bykA\n",
      "x9I5lAit11k\n",
      "eK1RvkTz93g\n",
      "mB0qIXMJyIs\n",
      "w-2ZgVedG_0\n",
      "li7uDQsi1OI\n",
      "5clRjfNiHoA\n",
      "wTKe3P1TzVY\n",
      "JORfxyg93uQ\n",
      "rZc4suHh21U\n",
      "d1Qh9-ok4UI\n",
      "HH-5zS4E6ts\n",
      "cL7YDBOZaPY\n",
      "pE-FNprmPPM\n",
      "D5PZn8YdKxM\n",
      "38gzcYHoxqM\n",
      "dsAT1NI0S0Q\n",
      "50EvFY019JA\n",
      "p_7_dtI0QKc\n",
      "JrXghzDFnD0\n",
      "A-x3ILbGo9w\n",
      "Kkp0Fedru-w\n",
      "H_9cm7ELIM4\n",
      "ZHbCG26me6I\n",
      "5MnoAsJ1Idg\n",
      "KdzTs2w-p2A\n",
      "Wxnv13wGZAg\n",
      "Y8v-jea5Gi0\n",
      "zPVZcvgB1P4\n",
      "9tv5clYvqOk\n",
      "hpJ_umfsdpA\n",
      "8nDV8snjSGY\n",
      "NI5oVNeA2cw\n",
      "fkJk_g9wag0\n",
      "fqLVb0Gb9G4\n",
      "1VwwLH5FCKs\n",
      "QW8CW6CXo54\n",
      "F29rbezLL94\n",
      "qt2xEQxcYsg\n",
      "Up5aADUVagU\n",
      "xcaSBHB9dbE\n",
      "pLsQVs5l87Y\n",
      "YUx-PavD7EA\n",
      "KRIpc_oN_zQ\n",
      "34LNfDnaNDw\n",
      "Igr_QCVGR-0\n",
      "-HV9VRPIoag\n"
     ]
    }
   ],
   "source": [
    "new_video_responses = get_uploaded_videos_response(youtube, channel['channelId'])\n",
    "list_of_new_video_responses_as_dicts = video_response_list_to_list_of_dicts(new_video_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_ids = [vid['videoId'] for vid in videos_collections]\n",
    "additional_responses = [v for v in list_of_new_video_responses_as_dicts if v['videoId'] not in existing_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(additional_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in additional_responses:\n",
    "#     docRef = db.collection(u\"videos\").document(u\"{}\".format(doc['videoId'])).set(doc)\n",
    "# videos_collections.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in videos_collections:\n",
    "    if 'mainTranscript' not in doc:\n",
    "        doc['mainTranscript']=''\n",
    "        docRef = db.collection(u\"videos\").document(u\"{}\".format(doc['videoId'])).set(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = [v for v in  videos_collections if v['videoId'] == 'gX0mrw1uZcY']\n",
    "# videos_wo_transcript=test\n",
    "# videos_collections=test\n",
    "videos_wo_transcript = [v for v in videos_collections if (v['mainTranscript'] == '')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(videos_wo_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,g = pullYtaTranscripts(videos_wo_transcript[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f),len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add assembly\n",
    "\n",
    "#if there is videos without assembly, select from them\n",
    "videos_wo_assembly_transcript = [v for v in videos_collections if ((v['assemblyText'] == '') and (v['availability'] != 'pending')) ]\n",
    "list_of_videos_less_30 = [v for v in videos_wo_assembly_transcript if v['duration'] <= 35*60]\n",
    "list_of_videos_for_assembly = list_of_videos_less_30[::2][4]\n",
    "list_of_videos_for_assembly_ids = [v['videoId'] for v in list_of_videos_for_assembly ]\n",
    "remaining_videos = [v for v in videos_wo_transcript if v['videoId'] not in list_of_videos_for_assembly_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: pull pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(getCost(list_of_videos_for_assembly),6), len(list_of_videos_for_assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitAssemblyTranscripts(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_new_pending_assembly_videos = [v for v in test if (v['availability'] =='pending')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_new_pending_assembly_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,g = pullAssemblyTranscripts(list_of_new_pending_assembly_videos) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f),len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,g = pullYtaTranscripts(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize in webapp\n",
    "#Use cases\n",
    "##find creators with certain categories\n",
    "##Correlate topics with likes/comments/engagement\n",
    "##See when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nothing\n",
    "#has yta\n",
    "#has assembly\n",
    "#has assembly pending"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
